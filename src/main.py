"""
Servidor MCP para bÃºsqueda semÃ¡ntica con Gemini y Supabase
"""
import asyncio
from typing import List, Dict, Any
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

from .gemini import gemini_client
from .supabase_client import supabase_client
from .config import config

# Crear servidor MCP
app = Server("fiscai-search-server")

@app.list_tools()
async def list_tools() -> List[Tool]:
    """Lista las herramientas disponibles"""
    return [
        Tool(
            name="search_documents",
            description="Busca documentos similares usando bÃºsqueda semÃ¡ntica con Gemini embeddings y Supabase",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Consulta de bÃºsqueda en lenguaje natural"
                    },
                    "limit": {
                        "type": "number",
                        "description": "NÃºmero mÃ¡ximo de documentos a retornar (default: 6)",
                        "default": 6
                    },
                    "threshold": {
                        "type": "number",
                        "description": "Umbral de similitud 0-1 (default: 0.6)",
                        "default": 0.6
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="generate_embedding",
            description="Genera un embedding vectorial para un texto usando Gemini AI",
            inputSchema={
                "type": "object",
                "properties": {
                    "text": {
                        "type": "string",
                        "description": "Texto para generar el embedding"
                    }
                },
                "required": ["text"]
            }
        )
    ]

@app.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:
    """Maneja las llamadas a las herramientas"""
    
    if name == "search_documents":
        query = arguments.get("query")
        limit = arguments.get("limit", config.TOPK_DOCUMENTS)
        threshold = arguments.get("threshold", config.SIMILARITY_THRESHOLD)
        
        if not query:
            return [TextContent(
                type="text",
                text="Error: Se requiere el parÃ¡metro 'query'"
            )]
        
        try:
            print(f"\nğŸ” Buscando: '{query}'")
            
            # Generar embedding de la consulta
            print("ğŸ“Š Generando embedding...")
            embedding = await gemini_client.generate_embedding(query)
            print(f"âœ… Embedding generado ({len(embedding)} dimensiones)")
            
            # Buscar documentos similares
            print("ğŸ” Buscando documentos similares...")
            documents = await supabase_client.search_similar_documents(
                embedding=embedding,
                limit=limit,
                threshold=threshold
            )
            
            if not documents:
                return [TextContent(
                    type="text",
                    text="No se encontraron documentos similares para la consulta."
                )]
            
            # Formatear resultados
            result = f"ğŸ“š Encontrados {len(documents)} documentos similares:\n\n"
            for i, doc in enumerate(documents, 1):
                similarity = doc.get('similarity', 0)
                title = doc.get('title', 'Sin tÃ­tulo')
                scope = doc.get('scope', 'N/A')
                content = doc.get('content', '')[:200] + '...'
                source = doc.get('source_url', 'N/A')
                
                result += f"{i}. **{title}** (Similitud: {similarity:.2%})\n"
                result += f"   - Ãmbito: {scope}\n"
                result += f"   - Contenido: {content}\n"
                result += f"   - Fuente: {source}\n\n"
            
            print(f"âœ… BÃºsqueda completada: {len(documents)} resultados")
            
            return [TextContent(type="text", text=result)]
            
        except Exception as e:
            error_msg = f"âŒ Error en la bÃºsqueda: {str(e)}"
            print(error_msg)
            return [TextContent(type="text", text=error_msg)]
    
    elif name == "generate_embedding":
        text = arguments.get("text")
        
        if not text:
            return [TextContent(
                type="text",
                text="Error: Se requiere el parÃ¡metro 'text'"
            )]
        
        try:
            print(f"ğŸ“Š Generando embedding para texto ({len(text)} caracteres)...")
            embedding = await gemini_client.generate_embedding(text)
            
            result = f"âœ… Embedding generado exitosamente\n"
            result += f"- Dimensiones: {len(embedding)}\n"
            result += f"- Primeros 5 valores: {embedding[:5]}\n"
            result += f"- Ãšltimos 5 valores: {embedding[-5:]}\n"
            
            return [TextContent(type="text", text=result)]
            
        except Exception as e:
            error_msg = f"âŒ Error generando embedding: {str(e)}"
            print(error_msg)
            return [TextContent(type="text", text=error_msg)]
    
    else:
        return [TextContent(
            type="text",
            text=f"Error: Herramienta desconocida '{name}'"
        )]


async def main():
    """Punto de entrada principal del servidor MCP"""
    print("ğŸš€ Iniciando servidor MCP FiscAI Search...")
    print(f"ğŸ“ Modelo Gemini: {config.GEMINI_MODEL}")
    print(f"ğŸ“ Dimensiones embedding: {config.EMBED_DIM}")
    print(f"ğŸ“ Umbral de similitud: {config.SIMILARITY_THRESHOLD}")
    print(f"ğŸ“ Top K documentos: {config.TOPK_DOCUMENTS}")
    print("=" * 50)
    
    async with stdio_server() as (read_stream, write_stream):
        await app.run(
            read_stream,
            write_stream,
            app.create_initialization_options()
        )


if __name__ == "__main__":
    asyncio.run(main())
